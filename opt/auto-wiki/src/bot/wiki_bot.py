# /opt/auto-wiki/src/bot/wiki_bot.py
# æ—¥æœ¬èªã‚¿ã‚¤ãƒˆãƒ«: è‡ªå¾‹å‹Wiki Bot (Deep Writer + Strict Mode)
# ç›®çš„: è¨˜äº‹ã‚’ç« ã”ã¨ã«åˆ†å‰²åŸ·ç­†ã™ã‚‹ã“ã¨ã§ã€Œæ·±ã¿ã€ã‚’å‡ºã—ã€ã‹ã¤ãƒãƒ£ãƒƒãƒˆåŒ–ã‚’å³æ ¼ã«é˜²æ­¢ã™ã‚‹

import os
import mwclient
import datetime
import json
import re
from openai import OpenAI
from src.bot.commons import CommonsAgent
from src.bot.vetter import InformationVetter
from src.bot.reviewer import ArticleReviewer
from src.bot.researcher import DeepResearcher
from src.rag.vector_store import WikiVectorDB

class LocalWikiBotV2:
    def __init__(self, wiki_host, bot_user, bot_pass, model_name, base_url, lang="ja"):
        print(f"ğŸ¤– Initializing WikiBot (Deep Writer & Strict Mode / Model: {model_name})...")
        self.lang = lang
        
        self.site = mwclient.Site(wiki_host, path='/', scheme='http')
        try:
            self.site.login(bot_user, bot_pass)
        except Exception as e:
            print(f"âš ï¸ Wiki Login Warning: {e}")
        
        self.client = OpenAI(base_url=base_url, api_key="ollama")
        self.model_name = model_name
        
        self.researcher = DeepResearcher(self.client, model_name, lang=lang)
        self.commons = CommonsAgent(self.client, model_name)
        self.vetter = InformationVetter(self.client, model_name, lang=lang)
        self.reviewer = ArticleReviewer(self.client, model_name, lang=lang)
        self.vector_db = WikiVectorDB()

    def update_article(self, topic: str):
        print(f"\nğŸ“˜ Processing Topic ({self.lang}): {topic}")

        # --- Phase 0: æ—¢å­˜è¨˜äº‹ã®ç¢ºèª ---
        page = self.site.pages[topic]
        old_text = ""
        is_existing = False
        
        if page.exists:
            print(f"   â„¹ï¸ Article '{topic}' already exists.")
            old_text = page.text()
            is_existing = True
        else:
            print(f"   ğŸ†• Creating NEW article: {topic}")

        # --- Phase 1: Deep Research ---
        try:
            # èª¿æŸ»ãƒ•ã‚§ãƒ¼ã‚ºï¼ˆã“ã“ãŒæƒ…å ±ã®ã€Œæ·±ã•ã€ã®æºæ³‰ï¼‰
            raw_research_text = self.researcher.conduct_deep_research(topic)
        except Exception as e:
            print(f"âŒ Research phase failed: {e}")
            return

        if not raw_research_text:
            print("âŒ No research results found.")
            return

        # --- Phase 2: ç”»åƒé¸å®š ---
        image_instruction = ""
        if not is_existing or ("[[File:" not in old_text and "[[ãƒ•ã‚¡ã‚¤ãƒ«:" not in old_text):
            try:
                images = self.commons.search_images(topic)
                best_image = self.commons.select_best_image(topic, images)
                if best_image:
                    clean_name = best_image.replace("File:", "")
                    image_instruction = f"[[File:{clean_name}|thumb|250px|{topic}]]"
            except Exception:
                pass

        # --- Phase 3: Writing (åŸ·ç­†) ---
        print(f"âœï¸  Starting Writing Process...")
        final_text = ""

        if is_existing:
            # æ—¢å­˜è¨˜äº‹ã¯æ§‹æˆã‚’å£Šã•ãªã„ã‚ˆã†ã€Œå·®åˆ†è¿½è¨˜ãƒ¢ãƒ¼ãƒ‰ã€ã§ä¸€æ‹¬å‡¦ç†
            final_text = self._write_incremental(topic, old_text, raw_research_text, image_instruction)
        else:
            # ã€é‡è¦ã€‘æ–°è¦è¨˜äº‹ã¯ã€Œåˆ†å‰²åŸ·ç­†ãƒ¢ãƒ¼ãƒ‰ã€ã§æ·±ã•ã‚’å‡ºã™
            final_text = self._write_deep_article(topic, raw_research_text, image_instruction)

        # --- Phase 4: Publishing (æŠ•ç¨¿) ---
        # ç°¡æ˜“ãƒã‚§ãƒƒã‚¯: æ˜ã‚‰ã‹ã«ãƒãƒ£ãƒƒãƒˆã£ã½ã„å¿œç­”ãŒå«ã¾ã‚Œã¦ã„ãªã„ã‹
        if final_text and len(final_text) > 50 and "Please provide" not in final_text:
            # ãƒãƒ£ãƒƒãƒˆå®šå‹æ–‡ã®é™¤å»ï¼ˆå¿µã®ãŸã‚ï¼‰
            final_text = self._clean_chat_artifacts(final_text)
            
            summary = "Created comprehensive article via Deep Writer." if not is_existing else "Updated with latest research."
            
            # æ—¢å­˜è¨˜äº‹ã¨å®Œå…¨ã«ä¸€è‡´ã—ãªã„å ´åˆã®ã¿ä¿å­˜
            if final_text.strip() != old_text.strip():
                page.save(final_text, summary=summary)
                print("âœ… Article published successfully.")
                self.vector_db.upsert_article(topic, final_text)
            else:
                print("â¹ï¸  No changes detected.")
        else:
            print("âŒ Output was invalid or chatty. Aborted.")

    def _write_deep_article(self, topic: str, context: str, image_inst: str) -> str:
        """
        ã€åˆ†å‰²åŸ·ç­†ãƒ­ã‚¸ãƒƒã‚¯ã€‘
        1. æ§‹æˆæ¡ˆï¼ˆç›®æ¬¡ï¼‰ã‚’ä½œæˆ
        2. å„ç« ã‚’å€‹åˆ¥ã«åŸ·ç­†
        3. çµåˆã—ã¦é•·æ–‡è¨˜äº‹ã‚’ç”Ÿæˆ
        """
        # Step 1: æ§‹æˆæ¡ˆã®ä½œæˆ
        print("   ğŸ“‘ Generating Outline...")
        outline = self._generate_outline(topic, context)
        print(f"   -> Sections: {outline}")
        
        full_article = ""
        
        # Step 2: å°å…¥éƒ¨ï¼ˆLead Sectionï¼‰ã®åŸ·ç­†
        # æ›¸ãå‡ºã—ã‚’å¼·åˆ¶ã—ã¦ãƒãƒ£ãƒƒãƒˆåŒ–ã‚’é˜²ã
        print("   ğŸ–Šï¸  Writing Introduction...")
        intro = self._write_section_strict(topic, "Introduction", context, image_inst, is_intro=True)
        full_article += intro + "\n\n"
        
        # Step 3: å„ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã®åŸ·ç­†
        for section in outline:
            print(f"   ğŸ–Šï¸  Writing Section: {section}...")
            section_content = self._write_section_strict(topic, section, context, "")
            full_article += section_content + "\n\n"
            
        # Step 4: é–¢é€£é …ç›®ã¨ã‚«ãƒ†ã‚´ãƒª
        full_article += self._generate_footer(topic)
        
        return full_article

    def _write_section_strict(self, topic: str, section_title: str, context: str, image_inst: str, is_intro: bool = False) -> str:
        """
        å„ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’åŸ·ç­†ã™ã‚‹ãƒ¡ã‚½ãƒƒãƒ‰ï¼ˆStrict Modeé©ç”¨ï¼‰
        """
        system_constraint = """
        [System Command]
        You are a text generation engine, NOT a chat assistant.
        - DO NOT talk to the user.
        - DO NOT say "Here is the article" or "Sure!".
        - DO NOT ask questions.
        - Output ONLY the requested Wikitext content.
        - Language: JAPANESE (æ—¥æœ¬èª)
        """

        if is_intro:
            # å°å…¥éƒ¨ï¼šå®šç¾©ã‹ã‚‰å¼·åˆ¶çš„ã«å§‹ã‚ã•ã›ã‚‹
            prompt = f"""
            {system_constraint}
            
            Task: Write the lead section for "{topic}".
            Input Data: {context[:6000]}
            Image Code: {image_inst}
            
            Instruction:
            - Start strictly with: '''{topic}'''
            - Write 3-5 summary sentences.
            - Insert the image code if provided.
            - NO headings here.
            """
        else:
            # å„ã‚»ã‚¯ã‚·ãƒ§ãƒ³
            prompt = f"""
            {system_constraint}
            
            Task: Write the section "{section_title}" for the article "{topic}".
            Input Data: {context[:6000]}
            
            Instruction:
            - Start strictly with: == {section_title} ==
            - Write detailed paragraphs (at least 400 characters).
            - Use bullet points only for lists.
            """
        
        try:
            resp = self.client.chat.completions.create(
                model=self.model_name,
                messages=[{"role": "user", "content": prompt}],
                temperature=0.3
            )
            content = resp.choices[0].message.content.strip()
            
            # Markdownã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯ã®é™¤å»
            content = content.replace("```wikitext", "").replace("```", "")
            
            return content
        except Exception as e:
            print(f"âš ï¸ Section write error: {e}")
            return f"== {section_title} ==\n(Content generation failed)"

    def _generate_outline(self, topic: str, context: str) -> list:
        """è¨˜äº‹ã®æ§‹æˆæ¡ˆï¼ˆã‚»ã‚¯ã‚·ãƒ§ãƒ³ãƒªã‚¹ãƒˆï¼‰ã‚’ä½œæˆ"""
        prompt = f"""
        List 4-6 main section titles for a Wikipedia article about "{topic}".
        Exclude "Introduction" and "See Also".
        Output ONLY a JSON list of strings. e.g. ["History", "Mechanism", "Impact"]
        Context: {context[:3000]}
        """
        try:
            resp = self.client.chat.completions.create(
                model=self.model_name,
                messages=[{"role": "user", "content": prompt}],
                temperature=0.3
            )
            content = resp.choices[0].message.content
            # JSONæŠ½å‡º
            if "[" in content and "]" in content:
                json_str = content[content.find("["):content.rfind("]")+1]
                return json.loads(json_str)
            return ["æ¦‚è¦", "æ­´å²", "ç‰¹å¾´"]
        except:
            return ["æ¦‚è¦", "æ­´å²", "ç‰¹å¾´"]

    def _write_incremental(self, topic, old_text, context, image_inst):
        """æ—¢å­˜è¨˜äº‹ã®è¿½è¨˜ç”¨ï¼ˆä¸€æ‹¬ç”Ÿæˆï¼‰"""
        # æ—¢å­˜ã®_build_incremental_update_promptã‚’ä½¿ç”¨
        prompt = self._build_incremental_update_prompt(topic, old_text, context, image_inst)
        try:
            resp = self.client.chat.completions.create(
                model=self.model_name,
                messages=[{"role": "user", "content": prompt}],
                temperature=0.3
            )
            return resp.choices[0].message.content.replace("```wikitext", "").replace("```", "")
        except:
            return old_text

    def _build_incremental_update_prompt(self, topic, old_text, info, image_inst):
        # æ—¢å­˜ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ§‹ç¯‰ãƒ­ã‚¸ãƒƒã‚¯ï¼ˆå¤‰æ›´ãªã—ï¼‰
        current_date = datetime.date.today().strftime("%Yå¹´%mæœˆ")
        return f"""
        ã‚ãªãŸã¯Wikipediaç·¨é›†è€…ã§ã™ã€‚æ—¢å­˜è¨˜äº‹ã€Œ{topic}ã€ã«æœ€æ–°æƒ…å ±ã‚’è¿½è¨˜ã—ã¦ãã ã•ã„ã€‚
        
        # ãƒ«ãƒ¼ãƒ«
        1. æ—¢å­˜ã®è¨˜äº‹ã¯æ›¸ãæ›ãˆãšã€ç¶­æŒã—ã¦ãã ã•ã„ã€‚
        2. æ–°ã—ã„æƒ…å ±ã®ã¿ã‚’é©åˆ‡ãªå ´æ‰€ã«è¿½è¨˜ã—ã¦ãã ã•ã„ã€‚
        3. å…¨æ–‡ï¼ˆå…ƒã®ãƒ†ã‚­ã‚¹ãƒˆ + è¿½è¨˜åˆ†ï¼‰ã‚’å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚
        
        # å…¥åŠ›æƒ…å ±
        {info[:5000]}
        
        # ç¾åœ¨ã®è¨˜äº‹
        {old_text}
        """

    def _generate_footer(self, topic):
        return f"== é–¢é€£é …ç›® ==\n* [[Wikipedia]]"
    
    def _clean_chat_artifacts(self, text):
        """AIãŒã¤ã„å‡ºåŠ›ã—ã¦ã—ã¾ã†ãƒãƒ£ãƒƒãƒˆã®æ®‹éª¸ã‚’é™¤å»"""
        lines = text.split('\n')
        clean_lines = []
        for line in lines:
            # "Here is the article" ãªã©ã‚’ç°¡æ˜“çš„ã«é™¤å¤–
            if "Here is" in line or "Sure," in line:
                continue
            clean_lines.append(line)
        return '\n'.join(clean_lines)

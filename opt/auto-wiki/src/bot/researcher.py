# /opt/auto-wiki/src/bot/researcher.py
# æ—¥æœ¬èªã‚¿ã‚¤ãƒˆãƒ«: æ·±å±¤ãƒªã‚µãƒ¼ãƒã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ (Parallelized)
# ç›®çš„: ãƒãƒ«ãƒã‚¹ãƒ¬ãƒƒãƒ‰åŒ–ã«ã‚ˆã‚Šæ¤œç´¢é€Ÿåº¦ã‚’å¤§å¹…ã«å‘ä¸Šã•ã›ãŸãƒªã‚µãƒ¼ãƒã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ

from duckduckgo_search import DDGS
from openai import OpenAI
import json
import concurrent.futures

class DeepResearcher:
    def __init__(self, client: OpenAI, model_name: str, lang: str = "ja"):
        self.client = client
        self.model_name = model_name
        self.lang = lang
        # DDGSã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã¯ã‚¹ãƒ¬ãƒƒãƒ‰ã‚»ãƒ¼ãƒ•ã§ãªã„å ´åˆãŒã‚ã‚‹ãŸã‚ã€ãƒ¡ã‚½ãƒƒãƒ‰å†…ã§ç”Ÿæˆæ¨å¥¨

    def conduct_deep_research(self, topic: str, max_sub_topics: int = 3) -> str:
        """
        ãƒˆãƒ”ãƒƒã‚¯ã«ã¤ã„ã¦æ·±å±¤èª¿æŸ»ã‚’è¡Œã†ãƒ¡ã‚¤ãƒ³ãƒ¡ã‚½ãƒƒãƒ‰ (ä¸¦åˆ—å‡¦ç†ç‰ˆ)
        """
        print(f"ğŸ•µï¸ Deep Researching for: {topic}")
        
        # Step 1: èª¿æŸ»è¨ˆç”»ã®ç«‹æ¡ˆ
        plan = self._create_research_plan(topic, max_sub_topics)
        print(f"   ğŸ“‹ Research Plan: {plan}")

        combined_results = []
        
        # æ¤œç´¢ã‚¯ã‚¨ãƒªã®ãƒªã‚¹ãƒˆä½œæˆï¼ˆãƒ¡ã‚¤ãƒ³ãƒˆãƒ”ãƒƒã‚¯ + ã‚µãƒ–ãƒˆãƒ”ãƒƒã‚¯ï¼‰
        queries = [topic] + [f"{topic} {sub}" for sub in plan]

        # Step 2 & 3: ä¸¦åˆ—æ¤œç´¢å®Ÿè¡Œ
        print(f"   ğŸš€ Executing {len(queries)} searches in parallel...")
        with concurrent.futures.ThreadPoolExecutor(max_workers=5) as executor:
            # å„ã‚¯ã‚¨ãƒªã«å¯¾ã—ã¦ _search ãƒ¡ã‚½ãƒƒãƒ‰ã‚’ä¸¦åˆ—å®Ÿè¡Œ
            future_to_query = {executor.submit(self._search, q): q for q in queries}
            
            for future in concurrent.futures.as_completed(future_to_query):
                query = future_to_query[future]
                try:
                    data = future.result()
                    combined_results.extend(data)
                    print(f"      âœ” Finished search for: {query}")
                except Exception as exc:
                    print(f"      âŒ Search failed for {query}: {exc}")

        # Step 4: çµæœã®é‡è¤‡æ’é™¤ã¨ãƒ†ã‚­ã‚¹ãƒˆåŒ–
        final_context = self._process_results(combined_results)
        return final_context

    def _create_research_plan(self, topic: str, count: int) -> list:
        """LLMã‚’ä½¿ã£ã¦èª¿æŸ»ã™ã¹ãã€Œã‚µãƒ–ãƒˆãƒ”ãƒƒã‚¯ï¼ˆè¦³ç‚¹ï¼‰ã€ã‚’ãƒªã‚¹ãƒˆã‚¢ãƒƒãƒ—ã™ã‚‹"""
        # (ã“ã“ã¯å¤‰æ›´ãªã—)
        if self.lang == "en":
            prompt = f"""
            To write a comprehensive Wikipedia article about "{topic}", what are the {count} most important sub-topics or aspects to research?
            Return ONLY a JSON list of short strings. Example: ["History", "Mechanism", "Criticism"]
            """
        else:
            prompt = f"""
            ã€Œ{topic}ã€ã«é–¢ã™ã‚‹åŒ…æ‹¬çš„ãªWikipediaè¨˜äº‹ã‚’æ›¸ããŸã‚ã«ã€èª¿æŸ»ã™ã¹ãé‡è¦ãªã€Œã‚µãƒ–ãƒˆãƒ”ãƒƒã‚¯ï¼ˆè¦³ç‚¹ï¼‰ã€ã‚’{count}ã¤æŒ™ã’ã¦ãã ã•ã„ã€‚
            ä¾‹: æ­´å²ã€ä»•çµ„ã¿ã€ãƒ¡ãƒªãƒƒãƒˆãƒ»ãƒ‡ãƒ¡ãƒªãƒƒãƒˆã€ç¤¾ä¼šçš„å½±éŸ¿
            ä½™è¨ˆãªèª¬æ˜ã¯ä¸è¦ã§ã™ã€‚JSONå½¢å¼ã®ãƒªã‚¹ãƒˆã®ã¿ã‚’è¿”ã—ã¦ãã ã•ã„ã€‚
            ä¾‹: ["æ­´å²", "æŠ€è¡“çš„ä»•çµ„ã¿", "èª²é¡Œ"]
            """

        try:
            resp = self.client.chat.completions.create(
                model=self.model_name,
                messages=[{"role": "user", "content": prompt}],
                temperature=0.3
            )
            raw_content = resp.choices[0].message.content
            content = raw_content.strip() if raw_content else "[]"
            
            if "```json" in content:
                content = content.split("```json")[1].split("```")[0]
            elif "```" in content:
                content = content.split("```")[1].split("```")[0]
            
            plan = json.loads(content)
            return plan[:count]
        except Exception as e:
            print(f"âš ï¸ Plan generation failed: {e}")
            return ["æ¦‚è¦", "æ­´å²", "ç‰¹å¾´"] if self.lang == "ja" else ["Overview", "History", "Features"]

    def _search(self, query: str, limit: int = 5) -> list:
        """æ¤œç´¢ã‚’å®Ÿè¡Œã™ã‚‹ãƒ˜ãƒ«ãƒ‘ãƒ¼ (ã‚¹ãƒ¬ãƒƒãƒ‰ã‚»ãƒ¼ãƒ•ã«ã™ã‚‹ãŸã‚éƒ½åº¦DDGSç”Ÿæˆ)"""
        results = []
        try:
            region = "jp-jp" if self.lang == "ja" else "us-en"
            # ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ã“ã“ã§ç”Ÿæˆã—ã¦ã‚¹ãƒ¬ãƒƒãƒ‰ç«¶åˆã‚’é˜²ã
            with DDGS() as ddgs:
                raw_res = ddgs.text(query, region=region, max_results=limit)
                if raw_res:
                    results.extend(raw_res)
        except Exception as e:
            print(f"âš ï¸ Search error for '{query}': {e}")
        return results

    def _process_results(self, raw_results: list) -> str:
        """æ¤œç´¢çµæœã‚’æ•´å½¢ãƒ»é‡è¤‡æ’é™¤ã—ã¦ãƒ†ã‚­ã‚¹ãƒˆåŒ–ã™ã‚‹"""
        seen_urls = set()
        formatted_text = ""
        blocked_domains = ["spam.com", "example.com"] 

        idx = 1
        for res in raw_results:
            url = res.get('href', '')
            # é‡è¤‡URLãŠã‚ˆã³ãƒ–ãƒ©ãƒƒã‚¯ãƒªã‚¹ãƒˆåˆ¤å®š
            if url in seen_urls or any(d in url for d in blocked_domains):
                continue
            
            seen_urls.add(url)
            title = res.get('title', 'No Title')
            body = res.get('body', '')
            
            formatted_text += f"[Source {idx}]\nTitle: {title}\nURL: {url}\nContent: {body}\n\n"
            idx += 1
            
            if idx > 20: # åé›†åŠ¹ç‡ãŒä¸ŠãŒã£ãŸã®ã§ä¸Šé™ã‚’å°‘ã—ç·©å’Œ
                break
                
        return formatted_text

# /opt/auto-wiki/src/bot/researcher.py
# æ—¥æœ¬èªã‚¿ã‚¤ãƒˆãƒ«: åå¾©å‹æ·±å±¤ãƒªã‚µãƒ¼ãƒã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ (Iterative Deep Research)
# ç›®çš„: æ¤œç´¢â†’åˆ†æâ†’ä¸è¶³æƒ…å ±ã®å†æ¤œç´¢ã¨ã„ã†ã‚µã‚¤ã‚¯ãƒ«ã‚’å›ã—ã€ç¶²ç¾…çš„ãªæƒ…å ±ã‚’åé›†ã™ã‚‹

from duckduckgo_search import DDGS
from openai import OpenAI
import json
import concurrent.futures

class DeepResearcher:
    def __init__(self, client: OpenAI, model_name: str, lang: str = "ja"):
        self.client = client
        self.model_name = model_name
        self.lang = lang

    def conduct_deep_research(self, topic: str, max_iterations: int = 2) -> str:
        """
        åå¾©å‹ã®æ·±å±¤èª¿æŸ»ã‚’è¡Œã†
        1. åˆæœŸèª¿æŸ»ï¼ˆåºƒç¯„å›²ï¼‰
        2. ä¸è¶³æƒ…å ±ã®åˆ†æã¨è¿½åŠ èª¿æŸ»ï¼ˆåå¾©ï¼‰
        """
        print(f"ğŸ•µï¸ Deep Researching for: {topic} (Iterative Mode)")
        
        # Phase 1: åˆæœŸèª¿æŸ» (Initial Breadth Search)
        # åŸºæœ¬çš„ãªè¦³ç‚¹ï¼ˆæ­´å²ã€æ¦‚è¦ã€ä»•çµ„ã¿ãªã©ï¼‰ã‚’ç¶²ç¾…ã™ã‚‹
        initial_plan = self._create_initial_plan(topic)
        print(f"   ğŸ“‹ Initial Plan: {initial_plan}")
        
        current_context = []
        queries = [topic] + [f"{topic} {sub}" for sub in initial_plan]
        current_context.extend(self._execute_parallel_search(queries))
        
        # Phase 2: åå¾©èª¿æŸ» (Iterative Depth Search)
        formatted_text = self._process_results(current_context)
        
        for i in range(max_iterations):
            print(f"   ğŸ”„ Iteration {i+1}/{max_iterations}: Analyzing missing information...")
            
            # ç¾åœ¨ã®æƒ…å ±ã§è¶³ã‚Šãªã„ã‚‚ã®ã‚’åˆ†æ
            missing_queries = self._identify_missing_info(topic, formatted_text)
            
            if not missing_queries:
                print("   âœ… Sufficient information gathered.")
                break
                
            print(f"   ğŸ” Digging deeper into: {missing_queries}")
            new_results = self._execute_parallel_search(missing_queries)
            
            if not new_results:
                print("   âš ï¸ No new info found.")
                break
                
            current_context.extend(new_results)
            # ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’æ›´æ–°ã—ã¦æ¬¡ã®ãƒ«ãƒ¼ãƒ—ã¸
            formatted_text = self._process_results(current_context)

        return formatted_text

    def _execute_parallel_search(self, queries: list) -> list:
        """ã‚¯ã‚¨ãƒªãƒªã‚¹ãƒˆã‚’ä¸¦åˆ—å®Ÿè¡Œã—ã¦çµæœã‚’è¿”ã™"""
        results = []
        with concurrent.futures.ThreadPoolExecutor(max_workers=5) as executor:
            future_to_query = {executor.submit(self._search, q): q for q in queries}
            for future in concurrent.futures.as_completed(future_to_query):
                try:
                    data = future.result()
                    if data:
                        results.extend(data)
                except Exception as e:
                    print(f"      âŒ Search error: {e}")
        return results

    def _create_initial_plan(self, topic: str) -> list:
        """åˆæœŸèª¿æŸ»è¨ˆç”»ã®ç«‹æ¡ˆ"""
        if self.lang == "en":
            prompt = f'List 4 essential sub-topics to understand "{topic}" as a JSON list. e.g. ["History", "Impact"]'
        else:
            prompt = f'ã€Œ{topic}ã€ã‚’Wikipediaãƒ¬ãƒ™ãƒ«ã§è§£èª¬ã™ã‚‹ãŸã‚ã«å¿…é ˆã¨ãªã‚‹4ã¤ã®è¦³ç‚¹ã‚’JSONãƒªã‚¹ãƒˆã§æŒ™ã’ã¦ãã ã•ã„ã€‚ä¾‹: ["æ­´å²", "ä»•çµ„ã¿", "å•é¡Œç‚¹", "ç¤¾ä¼šçš„å½±éŸ¿"]'

        return self._get_json_list(prompt)

    def _identify_missing_info(self, topic: str, current_text: str) -> list:
        """ç¾åœ¨ã®èª¿æŸ»çµæœã‚’è©•ä¾¡ã—ã€è¿½åŠ ã§èª¿ã¹ã‚‹ã¹ãå…·ä½“çš„ãªæ¤œç´¢ã‚¯ã‚¨ãƒªã‚’ç”Ÿæˆã™ã‚‹"""
        # ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãŒé•·ã™ãã‚‹å ´åˆã¯è¦ç´„ã—ã¦ã‹ã‚‰æ¸¡ã™ãªã©ã®å·¥å¤«ãŒå¿…è¦ã ãŒã€ã“ã“ã§ã¯å…ˆé ­4000æ–‡å­—ã§åˆ¤æ–­ã•ã›ã‚‹
        short_context = current_text[:4000]
        
        if self.lang == "en":
            prompt = f"""
            You are a rigorous researcher. Based on the "Current Notes", what critical information is missing to write a PERFECT Wikipedia article about "{topic}"?
            
            Current Notes:
            {short_context}...

            Output ONLY a JSON list of 3 specific search queries to find the missing details.
            If no more info is needed, output [].
            """
        else:
            prompt = f"""
            ã‚ãªãŸã¯å³æ ¼ãªãƒªã‚µãƒ¼ãƒãƒ£ãƒ¼ã§ã™ã€‚ã€Œç¾åœ¨ã®èª¿æŸ»ãƒ¡ãƒ¢ã€ã‚’ç¢ºèªã—ã€ãƒˆãƒ”ãƒƒã‚¯ã€Œ{topic}ã€ã«ã¤ã„ã¦å®Œç’§ãªè§£èª¬è¨˜äº‹ã‚’æ›¸ããŸã‚ã«ã€æ¬ ã‘ã¦ã„ã‚‹é‡è¦ãªæƒ…å ±ã€ã¯ä½•ã§ã™ã‹ï¼Ÿ
            
            ç¾åœ¨ã®èª¿æŸ»ãƒ¡ãƒ¢:
            {short_context}...

            ãã®æ¬ ã‘ã¦ã„ã‚‹æƒ…å ±ã‚’æ¢ã™ãŸã‚ã®ã€Œå…·ä½“çš„ãªæ¤œç´¢ã‚¯ã‚¨ãƒªã€ã‚’3ã¤ã€JSONãƒªã‚¹ãƒˆå½¢å¼ã§å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚
            ã“ã‚Œä»¥ä¸Šèª¿æŸ»ãŒä¸è¦ãªå ´åˆã¯ [] ã‚’å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚
            """
            
        return self._get_json_list(prompt)

    def _get_json_list(self, prompt: str) -> list:
        """LLMã‹ã‚‰JSONãƒªã‚¹ãƒˆã‚’å …ç‰¢ã«å–å¾—ã™ã‚‹ãƒ˜ãƒ«ãƒ‘ãƒ¼"""
        try:
            resp = self.client.chat.completions.create(
                model=self.model_name,
                messages=[{"role": "user", "content": prompt}],
                temperature=0.3
            )
            content = resp.choices[0].message.content.strip()
            # Markdownã‚¿ã‚°ã®é™¤å»
            if "```json" in content:
                content = content.split("```json")[1].split("```")[0]
            elif "```" in content:
                content = content.split("```")[1].split("```")[0]
            elif "[" not in content:
                return []
                
            return json.loads(content)
        except Exception:
            return []

    def _search(self, query: str, limit: int = 5) -> list:
        """DuckDuckGoæ¤œç´¢å®Ÿè¡Œ"""
        results = []
        try:
            region = "jp-jp" if self.lang == "ja" else "us-en"
            with DDGS() as ddgs:
                raw_res = ddgs.text(query, region=region, max_results=limit)
                if raw_res:
                    results.extend(raw_res)
        except Exception as e:
            print(f"âš ï¸ Search failed for '{query}': {e}")
        return results

    def _process_results(self, raw_results: list) -> str:
        """çµæœã®æ•´å½¢ï¼ˆé‡è¤‡æ’é™¤ãƒ»ãƒ–ãƒ©ãƒƒã‚¯ãƒªã‚¹ãƒˆé©ç”¨ï¼‰"""
        seen_urls = set()
        formatted_text = ""
        blocked = ["spam.com", "example.com"] 

        idx = 1
        for res in raw_results:
            url = res.get('href', '')
            if url in seen_urls or any(d in url for d in blocked):
                continue
            
            seen_urls.add(url)
            title = res.get('title', 'No Title')
            body = res.get('body', '')
            
            formatted_text += f"[Source {idx}] Title: {title}\nURL: {url}\nContent: {body}\n\n"
            idx += 1
            if idx > 30: break # Deepãƒ¢ãƒ¼ãƒ‰ãªã®ã§å°‘ã—å¤šã‚ã«è¨±å®¹
                
        return formatted_text
